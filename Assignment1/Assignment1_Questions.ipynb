{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Goals\n",
    "\n",
    "The goal of this assignment is to develop an understanding of how the brain performs computations at the neuronal level. To do so, you will develop several models of a spiking neuron. By the end of this assignment, you should a) be comfortable with developing models of spiking neurons at different levels of abstraction, from the biologically plausible H-H model to the phenomenological LIF model; b) understand how neurons use their firing rate to represent continuous-valued information; and c) understand the trade-offs involved in spike-based information representation. \n",
    "\n",
    "*More theoretical information can be found here: https://neuronaldynamics.epfl.ch/online/Ch2.html*\n",
    "\n",
    "Let's first import all the libraries required for this assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: The Hodgkin Huxley Neuron\n",
    "\n",
    "Before proceeding, please thoroughly review the [WIKI link](https://en.wikipedia.org/wiki/Hodgkin%E2%80%93Huxley_model)  and the research paper by Hodgkin and Huxley titled [Hodgkin A L, Huxley A F. A quantitative description of membrane current and its application to conduction and excitation in nerve, 1952](./HH.pdf). All necessary information for the Question 1 can be found in these sources. Additionally, please note the following:\n",
    "\n",
    "1. To ensure depolarization is interpreted as a positive event, indicating the influx of positive ions into a neuron resulting in increased positivity at points of equilibrium voltage or constant, the sign on relevant variables should be reversed.\n",
    "2. Utilize the formulas provided in the Wikipedia article as a framework for the code. (The formulas have been adjusted the notation in accordance with the reversal described in point 1).\n",
    "3. Attempt to comprehend the underlying logic derived from the formulas rather than solely seeking the solution. By doing so, you'll seize the chance to grasp the intricacies of Nobel Prize-worthy research.\n",
    "\n",
    "\n",
    "## 1a.\n",
    "\n",
    "We will start by implementing the different computational models of a spiking neuron, with the aim of understanding the differences between the different models. We will start with one of the earliest, yet one of the most biologically faithful models of a neuron - The Hodgkin-Huxley (HH) model. Below is the class definition of an HH neuron. Your first task is to fill the different components required to simulate an HH neuron.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HodgkinHuxley():\n",
    "    \"\"\"Implementation of Hodgkin Huxley Model\"\"\"\n",
    "    def __init__(self, C_m, g_Na, g_K, g_L, E_Na, E_K, E_L, T, dt, reset, I_inj):\n",
    "        \"\"\"\n",
    "        :param C_m: membrane capacitance in uF/cm^2\n",
    "        :param g_Na: Sodium conductance in mS/cm^2\n",
    "        :param g_K: Potassium conductance in ms/cm^2\n",
    "        :param g_L: Leak maximum conductance\n",
    "        :param E_Na: Sodium Nernst reversal potential in mV\n",
    "        :param E_K: Potassium Nernst reversal potential in mV\n",
    "        :param E_L: Leak Nernst reversal potential in mV\n",
    "        :param T: Simulation timesteps\n",
    "        :param dt: Integration time \n",
    "        :param reset: Reset potential\n",
    "        :param I_ink: injected current\n",
    "        \n",
    "        This function is complete. You do not need to do anything here.\n",
    "        \"\"\"\n",
    "        self.C_m = C_m \n",
    "        self.g_Na = g_Na \n",
    "        self.g_K = g_K\n",
    "        self.g_L = g_L\n",
    "        self.E_Na = E_Na\n",
    "        self.E_K = E_K\n",
    "        self.E_L = E_L\n",
    "        self.T = T\n",
    "        self.dt = dt\n",
    "        self.t = np.arange(0, self.T, self.dt) #*time to integrate over\n",
    "        self.n = np.zeros_like(self.t) #* history array to record all the \"n\"\n",
    "        self.m = np.zeros_like(self.t) #* history array to record all the \"m\"\n",
    "        self.h = np.zeros_like(self.t) #* history array to record all the \"h\"\n",
    "        self.V = np.zeros_like(self.t) #* history array to record all the \"V\"\n",
    "        self.reset = reset\n",
    "        self.I_inj = I_inj\n",
    "    \n",
    "    def alpha_m(self, V):\n",
    "        \"\"\"\n",
    "        Channel gating kinetics\n",
    "        :param V: membrane voltage\n",
    "        :return: alpha_m\n",
    "        \n",
    "        Fill in the equation for alpha_m\n",
    "        \"\"\"\n",
    "        return \n",
    "    \n",
    "    def beta_m(self, V):\n",
    "        \"\"\"\n",
    "        Channel gating kinetics\n",
    "        :param V: membrane voltage\n",
    "        :return: beta_m\n",
    "        \n",
    "        Fill in the equation for beta_m\n",
    "        \"\"\"\n",
    "        return \n",
    "    \n",
    "    def alpha_h(self, V):\n",
    "        \"\"\"\n",
    "        Channel gating kinetics\n",
    "        :param V: membrane voltage\n",
    "        :return: alpha_h\n",
    "        \n",
    "        Fill in the equation for alpha_h\n",
    "        \"\"\"\n",
    "        return \n",
    "    \n",
    "    def beta_h(self, V):\n",
    "        \"\"\"\n",
    "        Channel gating kinetics\n",
    "        :param V: membrane voltage\n",
    "        :return: beta_h\n",
    "        \n",
    "        Fill in the equation for beta_h\n",
    "        \"\"\"\n",
    "        return \n",
    "    \n",
    "    def alpha_n(self, V):\n",
    "        \"\"\"\n",
    "        Channel gating kinetics\n",
    "        :param V: membrane voltage\n",
    "        :return: alpha_n\n",
    "        \n",
    "        Fill in the equation for alpha_n\n",
    "        \"\"\"\n",
    "        return \n",
    "    \n",
    "    def beta_n(self, V):\n",
    "        \"\"\"\n",
    "        Channel gating kinetics\n",
    "        :param V: membrane voltage\n",
    "        :return: beta_n\n",
    "        \n",
    "        Fill in the equation for beta_n\n",
    "        \"\"\"\n",
    "        return \n",
    "    \n",
    "    def I_Na(self, V, m, h):\n",
    "        \"\"\"\n",
    "        Membrane Sodium current\n",
    "        :param V: membrane voltage\n",
    "        :param m: gating variable m\n",
    "        :param h: gating variable h\n",
    "        :return: sodium current I_Na\n",
    "        \n",
    "        Fill in the equation for I_Na\n",
    "        \"\"\"\n",
    "        return \n",
    "    \n",
    "    def I_K(self, V, n):\n",
    "        \"\"\"\n",
    "        Membrane Potassium current\n",
    "        :param V: membrane voltage\n",
    "        :param h: gating variable h\n",
    "        :return: Potassium current I_K\n",
    "        \n",
    "        Fill in the equation for I_K\n",
    "        \"\"\"\n",
    "        return \n",
    "    \n",
    "    def I_L(self, V):\n",
    "        \"\"\"\n",
    "        Membrane Leak current\n",
    "        :param V: membrane voltage\n",
    "        :return: Leak current I_L\n",
    "        \n",
    "        Fill in the equation for I_L\n",
    "        \"\"\"\n",
    "        return \n",
    "\n",
    "    \n",
    "    def update(self,t):\n",
    "        \"\"\"\n",
    "        Function to integrate membrane potential and activation variables by timestep t\n",
    "        :param t: timestep\n",
    "\n",
    "        \"\"\"\n",
    "        if t>0:\n",
    "            #* when timestep is not 0, update the \"n\", \"m\", \"h\", \"V\"\n",
    "            temp_I_Na = \n",
    "            temp_I_K =\n",
    "            temp_I_L = \n",
    "            I_ion =\n",
    "            self.V[t] =\n",
    "            self.n[t] =\n",
    "            self.m[t] =\n",
    "            self.h[t] =\n",
    "\n",
    "\n",
    "        else: \n",
    "            #* when t==0, INITIALIZE the necessary variables for the coming calculation\n",
    "            self.n[t] = \n",
    "            self.m[t] = \n",
    "            self.h[t] =\n",
    "\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Main function to simulate HH neuron and plot voltage and current against time. This part is complete. DO NOT change this code. You do not need to fill anything here. \n",
    "        \"\"\"\n",
    "        _ = [self.update(t) for t in range(len(self.t))]\n",
    "        self.V += self.reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b. \n",
    "Initialize an HH neuron using a proper set of parameters; then run the simulation. You should be able to get a plot depicting how the Voltage and Current of the neuron change with time. The result should looks like this ->\n",
    "\n",
    "\n",
    "![1b](./1b.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "(1. Initialize an hh neuron using the class definition above)\n",
    "You can find all the corresponding values in the paper\n",
    "Do not forget to reverse the signs of the one related to voltage!\n",
    "\"\"\"\n",
    "hh = HodgkinHuxley(\n",
    "    C_m=\n",
    "    g_Na=\n",
    "    g_K=\n",
    "    g_L=\n",
    "    E_Na=\n",
    "    E_K=\n",
    "    E_L=\n",
    "    T=100,\n",
    "    dt=0.01,\n",
    "    reset=-60,\n",
    "    I_inj=50,\n",
    ")\n",
    "#2. Run the hh neuron simulation\n",
    "hh.run()\n",
    "\n",
    "#3 plot it \n",
    "\"\"\"\n",
    "(DO NOT edit the plot code)\n",
    "\"\"\"\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 6))\n",
    "# plt.title(\"Hodgkin-Huxley Neuron\")\n",
    "ax1.axhline(0, color=\"k\", linestyle=\"--\", alpha=0.5)\n",
    "ax1.axhline(hh.reset, color=\"k\", linestyle=\"--\", alpha=0.5)\n",
    "ax1.plot(hh.t, hh.V, \"k\")\n",
    "ax1.set_ylabel(\"V\")\n",
    "ax1.set_ylim(-80, np.max(hh.V) + 10)\n",
    "ax1.set_xticks([])\n",
    "ax1.set_xticklabels([])\n",
    "I_inj = [hh.I_inj for t in hh.t]\n",
    "ax2.plot(hh.t, I_inj, \"k\")\n",
    "ax2.set_xlabel(\"t\")\n",
    "ax2.axhline(0, color=\"k\", linestyle=\"--\", alpha=0.5)\n",
    "ax2.set_ylabel(\"$I_{inj}$ ($\\\\mu{A}/cm^2$)\")\n",
    "ax2.set_ylim(-1, np.max(I_inj) + 10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1c. \n",
    "The beauty of a neurophysiologically accurate model of a neuron is that it allows the simulation of several phenomena that can take place in the brain. Assume that you administer a drug named Tetrodotoxin (TTX), which is a potent neurotoxin that inhibits the voltage-gated sodium channels, and therefore decreases the sodium current. Simulate the effects that administering TTX would have on the neural firing.  Do the same for another drug, pronase,\n",
    "which eliminates sodium inactivation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Initialize an hh neuron to simulate TTX\n",
    "\n",
    "#2. Run the hh neuron simulation\n",
    "\n",
    "#3. Initialize an hh neuron to simulate pronase\n",
    "\n",
    "#4. Run the hh neuron simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1d. (extra 10 points)\n",
    "\n",
    "Try to modify the code in the “HodgkinHuxley” class to dynamically show how the HH model will behave as the current magnitude increases. The expected gif results should look like ->\n",
    "\n",
    " ![here](./1d.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Change the color of Spike line to \"cyan\"\n",
    "2. the INJECTED current increases from -12 to 120\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: The Izhikevich Neuron\n",
    "\n",
    "## 2a.\n",
    "We will now implement an Izhikevich (Izhi) neuron model. Below is the class definition of an Izhi neuron. Like before, your task is to fill in the different components required to simulate an Izhi neuron. You should notice one key difference in the implementation: While our HH implementation relied on the odeint libary from scipy for integration, here we will use 'Euler's method' to integrate. The Euler's method is very intuitive, simple, and can be easily implemented. For your reference, the dynamics of an Izhi neuron are described in equations 1, 2, 3 in the paper: https://www.izhikevich.org/publications/spikes.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Izhi():\n",
    "    \"\"\"Implementation of the Izhikevich neuron Model\"\"\"\n",
    "    def __init__(self, a, b, c, d, Vth, T, dt):\n",
    "        \"\"\"\n",
    "        :param a, b, c, d: Izhi neuron parameters\n",
    "        :param Vth: Voltage threshold for spiking\n",
    "        :param T: Simulation timesteps\n",
    "        :param dt: Integration time \n",
    "        \n",
    "        This function is complete. You do not need to do anything here.\n",
    "        \"\"\"\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.c = c\n",
    "        self.d = d\n",
    "        self.Vth = Vth\n",
    "        self.u = self.b * self.c #initialize u\n",
    "        self.T = T\n",
    "        self.dt = dt\n",
    "        self.t = np.arange(0, self.T, self.dt)\n",
    "        self.I = 10 #Input stimulus current\n",
    "        \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Main function to simulate Izhi neuron and plot voltage and current against time. Fill in the update equations for du, dv, v[t] and u[t] and resetting on spiking.\n",
    "        \"\"\"\n",
    "        V = np.zeros(len(self.t)) #Initialize a numpy array containing the membrane voltages for all the timesteps\n",
    "        V[0] = self.c #Initial membrane voltage is the rest potential, defined by the parameter 'c'\n",
    "        u = np.zeros(len(self.t)) #Initialize a numpy array containing u for all the timesteps\n",
    "        u[0] = self.u #Initial u\n",
    "        \n",
    "        for t in range(1, len(self.t)): #the time loop for performing euler's integration\n",
    "            dv =  #compute increment in voltage\n",
    "            du =   #compute increment in u\n",
    "            V[t] =  #update the voltage\n",
    "            u[t] =  #update u\n",
    "            \n",
    "            #condition for when membrane potential is greater than the threshold\n",
    "            if V[t] >= self.Vth:\n",
    "                V[t] =  #reset v\n",
    "                u[t] =  #reset u\n",
    "                \n",
    "        #plotting\n",
    "        \"\"\"This function is complete. You do not need to do anything here\"\"\"\n",
    "        plt.figure()\n",
    "        plt.subplot(2,1,1)\n",
    "        plt.title('Izhi Neuron')\n",
    "        plt.plot(self.t, V, 'k')\n",
    "        plt.ylabel('V')\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.subplot(2,1,2)\n",
    "        i_inj = [self.I for t in self.t]\n",
    "        plt.plot(self.t, i_inj, 'k')\n",
    "        plt.xlabel('t')\n",
    "        plt.ylabel('$I_{inj}$ ($\\\\mu{A}/cm^2$)')\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. \n",
    "Initialize an Izhi neuron with the correct parameters and run the simulation. You should again be able to get a plot depicting how the Voltage and Current of the neuron change with time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Initialize an izhikevich neuron with the appropriate parameters\n",
    "\n",
    "#2. Run the simulation and obtain the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2c.\n",
    "Change the parameters of the Izhi neuron in the code to replicate two different patterns identified in neurons, e.g., bursting and adaptation. You can find the parameters for several different Izhi models here: https://www.izhikevich.org/publications/spikes.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your implementation of the bursting and chattering neuron here\n",
    "\n",
    "#1. Initialize an izhikevich neuron with the appropriate parameters\n",
    "\n",
    "#2. Run the simulation and obtain the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: The LIF Neuron\n",
    "\n",
    "## 3a. \n",
    "In this question, you will implement the almighty leaky integrate and fire neuron (LIF). The LIF neuron is the most widely-used model of a neuron in the SNN literature and you will be using it a lot for your course assignments and for your project. Below is the class definition of an LIF neuron. Just like the Izhi neuron, we will use Euler's method to perform integration. There is one key difference however: For HH and Izhi implementations, the neuron was taking current as the input. In our LIF implementation, the neuron takes spike-trains as inputs and produces spike-trains as output, similarly to how a real neuron works. \n",
    "\n",
    "As a hint, we provide here a discrete-time version of an LIF neuron:\n",
    "\n",
    "* First, integrate the input spikes into current with some decay factor\n",
    "\n",
    "$$C[t] = C[t-1] * current\\_decay + input\\_spike[t]$$\n",
    "\n",
    "* Then, integrate the current  into voltage with some decay factor\n",
    "\n",
    "$$V[t] = V[t-1] * voltage\\_decay + C[t]$$\n",
    "\n",
    "* Lastly produce a spike if the voltage exceeds the threshold, and reset voltage\n",
    "\n",
    "$$if V[t] >= Vth  \\\\ output\\_spike[t] = 1 \\ and \\ V[t] = Rest\\_Potential $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIF():\n",
    "    \"\"\"Implementation of Leaky integrate and fire neuron Model\"\"\"\n",
    "    def __init__(self, dc, dv, Vth, Vr):\n",
    "        \"\"\"\n",
    "        :param dc: Decay factor for current\n",
    "        :param dv: Decay factor for voltage\n",
    "        :param Vth: Voltage Threshold\n",
    "        :param Vr: Rest potential \n",
    "        \n",
    "        This function is complete. You do not need to do anything here\n",
    "        \"\"\"\n",
    "        self.dc = dc\n",
    "        self.dv = dv\n",
    "        self.Vth = Vth\n",
    "        self.Vr = Vr\n",
    "    \n",
    "    def run(self, in_spikes):\n",
    "        \"\"\"\n",
    "        Main function to simulate LIF neuron\n",
    "        :param in_spikes: Input spike train\n",
    "        :return out_spikes: output spike train\n",
    "        \n",
    "        Fill in the parts for updating Cm, Vm, and the condition for spiking and resetting\n",
    "        \"\"\"\n",
    "        Vm, Cm, out_spikes = [np.zeros(len(in_spikes)) for _ in range(3)] #initialize the state variables\n",
    "        for t in range(1, len(in_spikes)): #Time loop to perform Euler's Integration\n",
    "            Cm[t] =  #Integrate input spikes into current\n",
    "            Vm[t] =  #Integrate current into voltage\n",
    "            \n",
    "            #condition for when membrane potential is greater than the threshold\n",
    "\n",
    "        \n",
    "        return out_spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b. \n",
    "Based on the class definition above, create an LIF neuron with the following parameters: dc = 0.5, dv = 0.5, Vth = 0.50, Vr = 0. \n",
    "Then apply to the neuron a random spike train for 15 timesteps. You might find the following numpy package useful to generate the input spike train:\n",
    "https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html\n",
    "\n",
    "Simulate the neuron and print input and output spikes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Create an LIF neuron with the required parameters using the class definition above\n",
    "\n",
    "#2. Generate a random input spike train of 15 timesteps using the numpy random choice library function\n",
    "\n",
    "#3. Print the input spikes\n",
    "\n",
    "#4. Stimulate the LIF neuron with input spikes and return the output spikes\n",
    "\n",
    "#5. Print the output spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: Biology vs. Efficiency\n",
    "Now that you have simulated spiking neuron models at different levels of abstraction, we will learn how to differentiate between the three neuron models that we have developed, based on the following criteria:\n",
    "* Biological realism\n",
    "* Computational Efficiency\n",
    "\n",
    "Can you describe for what tasks might you need an HH model? For what tasks would an LIF neuron be a better alternative?\n",
    "*Hint*: Why one should use a neuron model that replicates several of the neuron's mechanisms vs. using a model that emulates the neuron as a spike-in-spike-out black box. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 4:\n",
    "Double click to enter your response to Question 4 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5: Tuning Membrane Properties of the LIF neuron\n",
    "## 5a.\n",
    "In this question, you will understand how to tune the membrane properties of an LIF neuron. First, generate 19 inputs in the form of random spike trains of length 50, i.e. 50 timesteps. The inputs will have different levels of probabilities for spike generation, that ranges between 0.1 and 1.0 with step size of 0.05. In other words, you will create 19 spike trains with the first spike train having the probability of 0.1 to generate spikes at any timestep, the second spike train will have the spike generation probability of 0.15, and so on. \n",
    "\n",
    "Simulate an LIF neuron with the parameters defined in Question 3b. You will now drive the neuron model with the 19 randomly generated input spike trains that you have created, and compute the output spike train. \n",
    "At the same time, compute the input firing rate and output firing rate for each simulation. Firing rate is defined as the mean of the spike train, i.e. total number of spikes/timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lif_behavior(lif):\n",
    "    \"\"\"Function to understand the behavior of LIF neuron for different densities of spike inputs\n",
    "    :param lif: An instance of the LIF neuron\n",
    "    \"\"\"\n",
    "    #1. Create lists to store the input and output firing rates\n",
    "    in_fr = [] #input firing rate\n",
    "    out_fr = [] #output firing rate\n",
    "    \n",
    "    #2. Create a list of probabilities: from 0.1 to 1.0 with step size of 0.05. You might find the numpy arange function helpful here.\n",
    "    probabilities = \n",
    "    \n",
    "    #3. Loop through the range of probabilities\n",
    "    for p in probabilities:\n",
    "        in_spikes =  #sample input spikes using np.random.choice function\n",
    "        \n",
    "        \n",
    "        #compute input firing rate and append to the in_fr list\n",
    "        \n",
    "        \n",
    "        #obtain output spikes by applying the input to the LIF neuron\n",
    "        \n",
    "        \n",
    "        #compute output firing rate and append to the out_fr list\n",
    "        \n",
    "\n",
    "    #Plot the input and output firing rates. Nothing to do here. This part is complete\n",
    "    plt.figure()\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.title('output firing rate')\n",
    "    plt.plot(out_fr, 'k')\n",
    "    plt.ylabel('Out F.R.')\n",
    "    plt.ylim([0,1])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(in_fr, 'k')\n",
    "    plt.ylabel('In F.R.')\n",
    "    plt.ylim([0,1])\n",
    "    plt.show()\n",
    "\n",
    "#Run the lif behavior function for the LIF neuron that we created previously\n",
    "lif_behavior(lif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5b. \n",
    "Describe how soon does the output firing rate start to saturate? Can you describe why this could be problematic? *Hint: Think from the point of view of distinguishing between two different inputs based on firing activity*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 5b.\n",
    "Write your response to Question 5b. here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5c. \n",
    "Change the membrane properties of the LIF neuron to resolve the issue of saturation. In other words, experiment on setting different parameter values that do not allow the output firing rate to saturate so early. *Hint: You may want to start by changing one variable at a time, and see its effect. Try to move it slightly, or abruptly, up or down. Then move to the next parameter, until you see what is its effect on the neuron's output.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Create an LIF neuron with appropriately tuned membrane properties\n",
    "\n",
    "#2. Call the lif behavior function on the tuned lif neuron\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5d.\n",
    "Based on the above results, can you describe how changing the H-H parameters changes the voltage threshold of a spiking neuron as a function of the input spikes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 5d.\n",
    "Double click to write your response to Question 5d. here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6: Encoding continuous inputs into spikes\n",
    "## 6a.\n",
    "Now we will understand how we can represent continuous-valued inputs as spikes so that drive our spiking neuron. Describe two prominent ways to encode a continuous-valued input into the spiking activity of a neuron. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 6a.\n",
    "Double click to write your response to Question 6a. here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6b. \n",
    "So far we have learned how we can stimulate a spiking neuron using spike inputs. In this exercise, you will learn how to encode real-world data into spikes that can then be fed as inputs to the spiking neuron. We will take a digit from the popular MNIST dataset as an example. First let's see what a sample digit from the MNIST image looks like. For this, we need to create a loader for the MNIST dataset using a Pytorch function called datasets.MNIST. You do not need to know what a loader is for now. Just understand the two important arguments of the function: The first argument is the directory where the MNIST dataset will be downloaded. The third argument is the set download option. This should be true for the first time when you run this cell to allow you to download the MNIST data into your directory. You can set it to false if the MNIST data has already been downloaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a loader\n",
    "mnist = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "#You can access any sample digit from the MNIST dataset using simple indexing mnist[idx]. This returns the digit and the label. We are only interested in the digit. \n",
    "x, _ = random.choice(mnist)\n",
    "# x, _ = mnist[24] # uncomment this line if you want to fix the target image\n",
    "\n",
    "#Convert to numpy\n",
    "x = x.numpy()[0]\n",
    "\n",
    "#Visualize\n",
    "plt.imshow(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now encode the image in the form of spikes using rate-encoding. Suppose that each pixel in the image needs to be encoded in a spike train of length 1. The steps to encode are outlined below:\n",
    "* For each pixel in the image, sample a random number.\n",
    "* If the pixel intensity is greater than the generated random number, output a spike. \n",
    "* Repeat for as many timesteps as you need to encode the image for. \n",
    "* Repeat for all pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0. Decide the number of spike train here. let us say n_spike = 1 here.\n",
    "\n",
    "\n",
    "#1. Use the numpy.random.rand function to encode the MNIST image into spikes\n",
    "\n",
    "\n",
    "#2. Output the shape of the spike-encoded image using numpy.shape (hint: the spike-encoded image should be a 3d arraay)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6c. \n",
    "Now, we will decode the image back from the spike-based representation. Can you think of a way to get the pixel values back? *Hint: Think aggregate measures on the spike trains for each pixel. Aggregation means compressing of the channel from n to 1.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Compute some aggregate measure of spike trains for each pixel to get the image back. Numpy aggregate functions might be useful here\n",
    "\n",
    "#2. visualize the reconstructed image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it possible to get the exact image back? Why/Why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 6c.\n",
    "Double click to write your response to Question 6c. here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6d. \n",
    "Can you think of a way to encode the image into spikes in a way such that the decoded image looks as close as possible to the original image? *Hint: Think timesteps*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Create a \"better\" encoding of the image\n",
    "\n",
    "#2. Compute and visualize the decoded image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If each intensity pixel is represented with a value between [0, 255], what would be a reasonable timestep to encode it accurately? What might be a disadvantage of this solution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 6d. \n",
    "Double click to write your response to Question 6d. here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6e\n",
    "\n",
    "Can you try at least **two** other aggregation functions to decode the images and describe the differences among them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 same struction as 6c\n",
    "\n",
    "\n",
    "#2 plot the results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer 6e. \n",
    "Double click to write your response to Question 6e. here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
